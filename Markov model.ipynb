{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6d02f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9449467",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello there, I am SJR. I love to sing and dance. My hobby is to listen to the music.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d92039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, I am SJR. I love to sing and dance. My hobby is to listen to the music.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(text.strip().split())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33843cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef310cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1df39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15484b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'there,',\n",
       " 'I',\n",
       " 'am',\n",
       " 'SJR.',\n",
       " 'I',\n",
       " 'love',\n",
       " 'to',\n",
       " 'sing',\n",
       " 'and',\n",
       " 'dance.',\n",
       " 'My',\n",
       " 'hobby',\n",
       " 'is',\n",
       " 'to',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'the',\n",
       " 'music.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d98af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = \" \".join(text for text in tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03cb5dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello there, i am sjr. i love to sing and dance. my hobby is to listen to the music.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d3bb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = normalized_text.replace(\".\",\"\").replace(\",\",\"\").lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1185e8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello there i am sjr i love to sing and dance my hobby is to listen to the music'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d09a2c",
   "metadata": {},
   "source": [
    "## Creating function for ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd175ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ng(text):\n",
    "    grams = []\n",
    "    arr = text.split()\n",
    "    i = 0\n",
    "    for x in arr:\n",
    "        temp = (arr[i],arr[i+1])\n",
    "        grams.insert(i,temp)\n",
    "        i=i+1 if i<len(arr)-2 else i\n",
    "    grams = grams[:-1]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4acb42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = ng(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "28f8e520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'there'),\n",
       " ('there', 'i'),\n",
       " ('i', 'am'),\n",
       " ('am', 'sjr'),\n",
       " ('sjr', 'i'),\n",
       " ('i', 'love'),\n",
       " ('love', 'to'),\n",
       " ('to', 'sing'),\n",
       " ('sing', 'and'),\n",
       " ('and', 'dance'),\n",
       " ('dance', 'my'),\n",
       " ('my', 'hobby'),\n",
       " ('hobby', 'is'),\n",
       " ('is', 'to'),\n",
       " ('to', 'listen'),\n",
       " ('listen', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'music')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d09f9",
   "metadata": {},
   "source": [
    "## Now, we have to develop the transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c6e0957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(normalized_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5e9d1b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f0e3c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = np.zeros((len(unique_words),len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5609fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f0437209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,fw in enumerate(unique_words):\n",
    "    for j,nw in enumerate(unique_words):\n",
    "        cnt = 0\n",
    "        for n in n_grams:\n",
    "            if n[0]==fw and n[1]==nw:\n",
    "                cnt += 1\n",
    "        tm[i][j] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b60cc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "50e74fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3f11ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_matrix = normalize(tm,axis=1,norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4a2a4543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30bb49",
   "metadata": {},
   "source": [
    "## Finally, the Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "25101d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_generator(in_word,length):\n",
    "    initial_word = in_word\n",
    "    completed_word = \"\"\n",
    "\n",
    "    i_word = initial_word\n",
    "\n",
    "    for i in range(length):\n",
    "        index = unique_words.index(initial_word)\n",
    "        best_probable_word_idx = np.argmax(norm_matrix[index])\n",
    "        best_probable_word = unique_words[best_probable_word_idx]\n",
    "        completed_word += \" \" + best_probable_word\n",
    "        initial_word = best_probable_word\n",
    "    #print(i_word,completed_word)\n",
    "    generated_content = i_word+\" \"+completed_word\n",
    "    return generated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8050ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = markov_generator(\"i\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "96310286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  love to sing and dance\n"
     ]
    }
   ],
   "source": [
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13522d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a05db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
